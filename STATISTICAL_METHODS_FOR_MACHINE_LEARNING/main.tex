\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{cancel}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{forest}
%\usepackage{imakeidx}



\title{STATISTICAL METHODS \\FOR MACHINE LEARNING}
\author{giosumarin}
\date{March 2021}
\makeindex


\begin{document}

\maketitle

\tableofcontents


\section{Lezione 1}
\begin{itemize}
	\item clustering: raggruppare punti in accordo alla loro similarità (raggruppare clienti per soldi spesi);
	\item classification: predirre label semantiche associate ai data points (classificare documenti per argomento);
	\item planning: vogliamo decidere una sequenza di azioni che devono essere fatte per raggiungere un goal (robot che va da quache parte con ostacoli sul percorso o guida autonoma).
	\item supervised learning: abbiamo laber per degli esempi e imparo a classificare d questi
	\item unsupervised learning: clustering (label "attaccata" ai data points)
\end{itemize}

\subsection{Label set}
\begin{itemize}
	\item $Y$ label set
	\item news classification: $Y$=\{sport, politica, business, $\dots$\}
	\item predizione stock price: $Y \in \mathbb{R}$
	\item classification/categorization: $Y$ insieme finito di simboli, $\hat{y} \overset{?}{=}y$, con $\hat{y}$ predizione e $y$ valore reale;
	\item regression: $Y \in \mathbb{R}$, $|\hat{y}-y|$.
\end{itemize}

\subsection{Loss function}
\begin{displaymath}
	\begin{split}
		&l(y, \hat{y})=\begin{cases}
			&0 \textit{ se } y= \hat{y}\\
			&1 \textit{ altrimenti}
		\end{cases}\\
		&Y=\{ \textit{spam (positivo)}, \textit{nonspam (negativo)} \}, \textit{binary classification problem} \\
		&l(y, \hat{y})=\begin{cases}
			&2 \textit{ se } y= \textit{nonspam e }\hat{y} = \textit{spam} \leftarrow \textit{ falso positivo} \\
			&1 \textit{ se } y= \textit{spam e }\hat{y} = \textit{nonspam} \leftarrow \textit{ falso positivo} \\
			&0 \textit{ altrimenti}						
		\end{cases} \\
		&\textit{absolute loss (per regressione): } l(y, \hat{y})= |\hat{y}-y| \\ 
		&\textit{square loss (per regressione): } l(y, \hat{y})= (\hat{y}-y)^2 \\
		& \\
		&\textit{[ESEMPIO] previsioni meteo: }Y=\{ \textit{pioggia}, \textit{asciutto} \}\\ 
		&\hat{y}=\textit{probabilità assegnata a pioggia}; \textit{ prediction set: } Z=\{0,1\} \\
		&l(y, \hat{y})=|\hat{y}-y| \\
		&l(y, \hat{y}) = \begin{cases}
				&\ln \frac{1}{\hat{y}} \textit{ se } y=1 \\
				&\ln \frac{1}{1-\hat{y}} \textit{ se } y=0 \\
			\end{cases}
	\end{split}
\end{displaymath}
La loss logaritmica ha le seguenti proprietà:
\begin{itemize}
	\item $\lim\limits_{\hat{y}\rightarrow 0^+}l(1,\hat{y})=\infty$
	\item $\lim\limits_{\hat{y}\rightarrow 1^-}l(0,\hat{y})=\infty$
\end{itemize} 

\section{Lezione 2}
\subsection{Data Points}
$X$ dominio dati, $x$ spesso è codificato convenientemente come vettore di numeri attravero per esempio la one-hot encoding.
\begin{displaymath}
	X=
	\begin{cases}
		&\mathbb{R}^d \textit{ attributi numerici} \\
		&X_1,\dots, X_d \textit{ attributi categorici}
	\end{cases}
\end{displaymath}
Possiamo avere anche un mix di diversi attributi.

\subsection{Predictor}
Un predittore è una funzione che mappa data points in label
\begin{displaymath}
	\begin{split}
		f: X \rightarrow Y, f: X \rightarrow \overline{Z}, \overline{Z} \neq Y 
	\end{split}
\end{displaymath}
Dato un ponto $x$ abbiamo quindi
\begin{displaymath}
	\hat{y}=f(x).
\end{displaymath}
Quello che vogliore è avere una loss piccola per molti $x \in X$.
\subsection{Supervised learning}
Abbiamo le coppie $(x,y)$ con $x$ singolo data point e $y$ la sua rispettiva label. Le label possono essere soggettive (annotazioni umane) o ogettive (misurazioni di strumenti).
\subsubsection{Training Set}
Insieme di esempi su cui effettuiamo l'addestramento; abbiamo quindi un training set in input a un algoritrmo di apprendimento (con la sua loss) e che in output genera un predittore.
\subsubsection{Test Set}
Insieme di esempi ($\neq$ training set) su cui viene valutata la capacità di generalizzazione di un predittore addestrato sul training set.

\subsubsection{Completo}
Abbiamo il predittore $f$ uscente dall'algoritmo di apprendimento $A$ usando la funzione di loss $l$. Abbiamo il test set $(x_1',y_1'),\dots, (x_n',y_n')$, calcoliamo il nostro test error come
\begin{displaymath}
	\frac{1}{n} \sum\limits_t^n l(y_t', f(x_t')).
\end{displaymath}  
Il nostro goal è quello di sviluppare una teoria per guidare nel design di $A$ che ci genera predittori con un piccolo test error w.r.t. una loss function.
\subsection{Empirical Risk Minimizer}
Fisso un insieme $F$ di predittori e una loss function $f$. Entra quindi il training set ($S$) in questo ERM (che ha $F$ e $l$) e abbiamo in output
\begin{displaymath}
	\hat{f} \in arg\min\limits_{f \in F} \hat{l_S}(f).
\end{displaymath}
L'idea è di minimizzare il training error in una classe $F$ di predittori.
Se $\min\limits_{f \in F} \frac{1}{n} \sum\limits_{t=1}^{n}l(y_t', f(x_t'))$ è grande siamo in un caso di \underline{underfitting}.
\subsubsection{Esempio}
Prendiamo $F$ grande e vediamo cosa succede.

\begin{displaymath}
	\begin{split}
		&X= \{ x_1,\dots, x_5 \}, Y= \{ -1,1 \}, F \textit{ contiene tutti i classificatori binari} \\
		&|F|=2^5=32, \exists f^* \textit{ t.c. } y_t=f^*(x_t) \textit{ con } t=\{ 1,\dots, 5 \}
	\end{split}
\end{displaymath}
\begin{table}[]
\begin{tabular}{l|ccccc}
\cline{2-6}
                            & \multicolumn{1}{c|}{$x_1$} & \multicolumn{1}{c|}{$x_2$} & \multicolumn{1}{c|}{$x_3$} & \multicolumn{1}{c|}{$x_4$} & \multicolumn{1}{c|}{$x_5$} \\ \hline
\multicolumn{1}{|l|}{$f^*$} & -1                         & 1                          & 1                          & $f^*(x_4)$                 & $f^*(x_5)$                 \\ \cline{1-1}
\multicolumn{1}{|l|}{$f^1$} & -1                         & 1                          & 1                          & 1                          & 1                          \\ \cline{1-1}
\multicolumn{1}{|l|}{$f^2$} & -1                         & 1                          & 1                          & -1                         & 1                          \\ \cline{1-1}
\multicolumn{1}{|l|}{$f^3$} & -1                         & 1                          & 1                          & 1                          & -1                         \\ \cline{1-1}
\multicolumn{1}{|l|}{$f^4$} & -1                         & 1                          & 1                          & -1                         & -1                         \\ \cline{1-1}
\end{tabular}
\end{table}
Se il training set è formato dai primi 3 data point tutti e 4 i predittori hanno lo stesso training error uguale a 0. In questo caso non possiamo decidere quale predittore usare. Chiamo questo caso \underline{overfitting}.



Possiamo estrapolare la seguente regola da questo esempio (quando $F$ è finito):
\begin{displaymath}
	m \geq \log_2|F|
\end{displaymath}

\section{Lezione 3}
\subsection{Overfitting e Underfitting}
Overfitting: Training error basso ma test error alto (nel caso di ERM $|F|$ grande).



Underfitting: Training error alto e test error vicino al training error.
\subsection{Noisy label}
In pratica non c'è $f^*:X \rightarrow Y$ tale che $f^*(x)=y$ per tutti gli esempi $(x,y)$. $y$ ha un disturbo dato $x$: stessi datapoint possono avere diverse label.
\begin{itemize}
	\item Human in the loop: persone categorizzano diversamente i dati;
	\item Lack of information: le informazioni contenute nei datapoint $X$ non sono sufficienti per determinare un'unica label
\end{itemize}
Noisy label provoca overfitting.
\subsection{Nearest Neighbor}
Classifica i punti usando la label del training point più vicino.
Averno $x=(x_1, \dots, x_d)$ con $d$ coordinate per punto calcoliamo la distanza euclidea per ogni dimensione: $||x-x'||=\sqrt{\sum\limits_i^d (x_i-x_i'}$. NN genera un predittore con training error sempre a 0, devo salvare tutto il training set per fare la predizione. 



$k$-NN: come NN ma usa la maggioranza delle label dei $k$ vicini data points. $k$ viene scelta dispari per non avere un numero pari di vicini nel punto del test che voglio classificare. Quindi guardo i $k$ più vicini al punto che sto valutando e vince la maggioranza. Per classificazione uso più label (il caso generico è spiegato su classificazione binaria), per regressione faccio la media dei $k$ più vicini.

\section{Lezione 4}
\subsection{Tree Predictor}
NN funziona solo per attributi numerici. Abbiamo un albero in cui i nodi interni sono taggati come test e i nodi foglia solo label. Per esempio abbiamo
\begin{displaymath}
	\begin{split}
		&X_i=\{a,b,c,d \} \\
		&f(X_i)=
			\begin{cases}
				&1 \textit{ se } x_1=a \\
				&2 \textit{ se } x_2=b \\
				&3 \textit{ altrimenti}
			\end{cases}
	\end{split}
\end{displaymath}
I valori del sistema indicano a quale nodo devo andare. Posso avere confronti su attributi categorici o soglie suattributi $\in \mathbb{R}$.



Dato un training set $S$, come costruisco un tree classificator?
\begin{itemize}
	\item $Y={-1,1}$;
	\item albero binario compreto (0 o 2 figli);
	\item $0-1$ loss;
	\item $S=(x_1,y_1), \dots, (x_m,y_m)$.
\end{itemize}
Partiamo da un classificatore binario costante che classifica tutti allo stesso modo, ovvero uso la maggioranza per assegnare la label alla foglia. Splitto ora questa foglia in due foglie e pongo un test nel classificatore costante iniziale. Ricordiamo che un test è fatto su una sola dimensione dell'input. Partiziono il training set $S$ in due: $S_l$ e $S_l'$ a cui corrispondono rispettivamente le labl $y_l$ e $y_l'$. Defininiamo $N_l=|S_l|$ dove $y_l$ è in maggioranza in $S_l$.



Definiamo ora $S_l^+=\{ (x_t,y_t) \in S_l: y_t=+1 \}$ e $S_l^-=\{ (x_t,y_t) \in S_l: y_t=-1 \}$.
\begin{displaymath}
	\begin{split}
		& y_l=\begin{cases}
			+1 &\textit{ se } N_l^+ \geq N_l^- \\
			-1 &\textit{ altrimenti}		
		\end{cases}	\\	
		& \mathbb{I}=\begin{cases}
			1 &\textit{ se vero} \\
			0 &\textit{ altrimenti}
		\end{cases} \\
		&\hat{l}_s(h_T) = \frac{1}{m}	\sum\limits^m_{t=1} \mathbb{I} \{ h_T(x_t) \neq y_t \} =\\
		&= \frac{1}{m}\sum\limits_l \min \{ N_l^+, N_l^- \} =
	\end{split}
\end{displaymath}
(l'ultimo passaggio è perchè alla label associo la maggioranza, con $l$ nella sommatoria ciclo sui nodi foglia. Considerando che $\frac{N_l^+}{N_l}+\frac{N_l^-}{N_l}=1$ e che $\sum\limits_l (N_l^++N_l^-)=m=|S|$)
\begin{displaymath}
	= \frac{1}{m} \sum\limits_l \min
\end{displaymath}







\end{document}
